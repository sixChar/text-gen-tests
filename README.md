# text-gen-tests

Several different text models implemented in pytorch and trained on the [Blog Authorship Corpus](https://www.kaggle.com/rtatman/blog-authorship-corpus) dataset to predict the next character.

## Models implemented:
- LSTM
- Linear Transformer (sort of, it's very simplified and does much worse than LSTM but it's still learning a bit so I'm counting it)

## TODO:
- Implement a more complicated fast weight programmer model
- (Maybe) Implement a self programmin fast weight programmer model
