# text-gen-tests

Several different text models implemented in pytorch and trained on the [Blog Authorship Corpus](https://www.kaggle.com/rtatman/blog-authorship-corpus) dataset to predict the next character.

## Models implemented:
- LSTM
- Linear Transformer (sort of, it's very simplified and does much worse than LSTM but it's still learning a bit so I'm counting it)
- Fast weight programmer model with feed forward slow and fast nets.
- Fast weight programmer model with LSTM slow net and feed forward fast net.

